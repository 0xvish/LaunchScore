# -*- coding: utf-8 -*-
"""Startup_Success_2.0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P6UrfDhJFrpdiJOagb1aplYMPZqcEZZx
"""

!pip install langchain kagglehub faiss-cpu sentence-transformers openai

!pip install langchain_community

import kagglehub
import pandas as pd

# Download dataset
path = kagglehub.dataset_download("omkargowda/indian-startups-funding-data")
print("Path to dataset files:", path)

# # Load CSV
df = pd.read_csv(f"{path}/startup_funding2021.csv")
df = df.dropna(subset=["What it does"])
df = df.reset_index(drop=True)

# # Show a preview
df[["Company/Brand", "What it does", "Amount($)", "Stage"]].head()

from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings

# Use MiniLM for embedding
embedding_model = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

texts = df["What it does"].tolist()
metadatas = df.to_dict("records")

vectorstore = FAISS.from_texts(texts=texts, embedding=embedding_model, metadatas=metadatas)
vectorstore.save_local("startup_faiss_index")

retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

# Example label: 1 if Series A+ or amount > $1M, else 0
df['is_success'] = pd.to_numeric(df['Amount($)'].str.replace('[\$,]', '', regex=True), errors='coerce').fillna(0) > 1000000
df['is_success'] |= df['Stage'].fillna('').str.contains('Series [A-Z]', regex=True)
df['is_success'] = df['is_success'].astype(int)

from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer

features = ['Sector', 'Stage', 'HeadQuarter']
X = df[features]
y = df['is_success']

preprocessor = ColumnTransformer([
    ('cat', OneHotEncoder(handle_unknown='ignore'), features)
])

model = Pipeline([
    ('preprocess', preprocessor),
    ('clf', LogisticRegression())
])

X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)
model.fit(X_train, y_train)

# # prompt: print the catogories with their one hot encoding

# import pandas as pd
# from sklearn.preprocessing import OneHotEncoder

# # Assuming 'df' and 'features' are defined as in the previous code

# # Create the OneHotEncoder object
# encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)

# # Fit the encoder on the categorical features
# encoder.fit(df[features])

# # Transform the features into one-hot encoded vectors
# encoded_features = encoder.transform(df[features])

# # Get the feature names after one-hot encoding
# encoded_feature_names = list(encoder.get_feature_names_out(features))

# # Create a DataFrame with the one-hot encoded features
# encoded_df = pd.DataFrame(encoded_features, columns=encoded_feature_names)

# # Print the categories and their one-hot encoding representation
# for col in features:
#   print(f"\nCategory: {col}")
#   categories = encoder.categories_[features.index(col)]
#   for i, category in enumerate(categories):
#     encoded_col_name = f"{col}_{category}"
#     print(f"  {category}: {encoded_df[encoded_col_name].values}")

import os
os.environ["GOOGLE_API_KEY"] = "AIzaSyCI6r8rXI0TvtQ5JsuiQAZ2LbXXskrqvcI"  # ← Replace with your key

!pip install langchain_experimental langchain-google-genai

from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain_google_genai import ChatGoogleGenerativeAI

llm = ChatGoogleGenerativeAI(
    model="models/gemini-1.5-flash-latest",
    temperature=0.5
)

prompt = PromptTemplate(
    input_variables=["context", "question"],
    template="""
You are a startup venture analyst with deep knowledge of market trends, startup funding, and investor behavior.

You are provided with descriptions and funding data of similar startups:

{context}

A new startup idea has been proposed:

"{question}"

Your tasks:
1. Analyze the idea and compare it with the retrieved startups.
2. Evaluate market demand, originality, competition, and funding trends.
3. Predict its likelihood of success on a scale of 0 to 10.
4. Justify the score with a brief analysis including potential risks and advantages.

Format your response like this:

Success Score: <score>/10
Reasoning:
- <Insight 1>
- <Insight 2>
- ...

Be clear, concise, and objective.
"""
)


qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    chain_type="stuff",
    chain_type_kwargs={"prompt": prompt}
)

idea = "A blockchain-based platform to verify college degrees globally"
llm_response = qa_chain.run(idea)

# Extract score
import re
match = re.search(r'(\d+(?:\.\d+)?)\/10', llm_response)
llm_score = float(match.group(1)) if match else None

# Manually mapped for now
idea_features = pd.DataFrame([{
    'Sector': 'EdTech',
    'Stage': 'Seed',
    'HeadQuarter': 'Mumbai'
}])

ml_score = model.predict_proba(idea_features)[0][1] * 10  # Convert to 0–10 scale

final_score = 0.5 * llm_score + 0.5 * ml_score
print(f"LLM Score: {llm_score:.1f}, ML Score: {ml_score:.1f}, Final Score: {final_score:.1f}/10")

import matplotlib.pyplot as plt

plt.bar(['LLM', 'ML', 'Blended'], [llm_score, ml_score, final_score], color=['blue', 'green', 'purple'])
plt.title('Hybrid Startup Success Score')
plt.ylabel('Score (0–10)')
plt.show()

from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve

# Predict on test set
y_pred = model.predict(X_test)
y_proba = model.predict_proba(X_test)[:, 1]

print("Classification Report:")
print(classification_report(y_test, y_pred))

print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

print("AUC-ROC Score:", roc_auc_score(y_test, y_proba))

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay

cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)

plt.figure(figsize=(6, 6))
disp.plot(cmap='Blues')
plt.title("Confusion Matrix")
plt.grid(False)
plt.show()

fpr, tpr, thresholds = roc_curve(y_test, y_proba)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'AUC = {roc_auc_score(y_test, y_proba):.2f}', color='green')
plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.grid(True)
plt.show()

from sklearn.metrics import precision_recall_curve

precision, recall, _ = precision_recall_curve(y_test, y_proba)

plt.figure(figsize=(8, 6))
plt.plot(recall, precision, marker='.', color='darkorange')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.grid(True)
plt.show()

import joblib

# Save model to file
joblib.dump(model, 'ml_model.pkl')
print("ML model saved successfully.")

import joblib

# Save the complete pipeline
joblib.dump(model, 'ml_pipeline.pkl')
print("✅ ML pipeline saved successfully.")

vectorstore.save_local("models/startup_faiss_index")
print("✅ FAISS index saved at models/startup_faiss_index/")

